{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "import lightning as pl\n",
    "from train import LightningModel, get_config_for_dataset\n",
    "from bronze_age.config import LayerType\n",
    "\n",
    "from bronze_age.datasets import DatasetEnum, get_dataset\n",
    "\n",
    "dataset_enum = DatasetEnum.SIMPLE_SATURATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = get_config_for_dataset(dataset_enum)\n",
    "config.layer_type = LayerType.BronzeAgeGeneralConcept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = get_dataset(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LightningModel(\n",
       "  (model): StoneAgeGNN(\n",
       "    (input): InputLayer(\n",
       "      (lin1): Linear(in_features=3, out_features=3, bias=True)\n",
       "    )\n",
       "    (output): PoolingLayer(\n",
       "      (lin2): MLP(\n",
       "        (lins): ModuleList(\n",
       "          (0): Linear(in_features=6, out_features=16, bias=True)\n",
       "          (1): Linear(in_features=16, out_features=2, bias=True)\n",
       "        )\n",
       "        (bns): ModuleList(\n",
       "          (0): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (stone_age): ModuleList(\n",
       "      (0): BronzeAgeGNNLayerConceptReasoner(3, 3)\n",
       "    )\n",
       "  )\n",
       "  (train_accuracy): MulticlassAccuracy()\n",
       "  (val_accuracy): MulticlassAccuracy()\n",
       "  (test_accuracy): MulticlassAccuracy()\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LightningModel(num_classes=dataset.num_classes, num_node_features=dataset.num_node_features, config=config)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        ...,\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0].x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        ...,\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.]], grad_fn=<ArgMaxBackward>)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    model.model.input.lin1.weight[:] = torch.eye(model.model.input.lin1.weight.shape[0])\n",
    "    model.model.input.lin1.bias[:] = 0.0\n",
    "\n",
    "model.eval()\n",
    "model.model.input.forward(dataset[0].x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BronzeAgeGNNLayerConceptReasoner(3, 3)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.model.stone_age[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([True, True, True,  ..., True, True, True])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0].y == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "bounding_parameter = 10\n",
    "threshold = 7\n",
    "magical_idx = 3 + 1 * bounding_parameter + threshold  \n",
    "with torch.no_grad():\n",
    "    model.model.stone_age[0].concept_reasoner.filter_nn.weight[:] = -10000.0\n",
    "    model.model.stone_age[0].concept_reasoner.filter_nn.weight[magical_idx, 0] = 10000.0\n",
    "    model.model.stone_age[0].concept_reasoner.filter_nn.weight[magical_idx, 1] = 10000.0\n",
    "    model.model.stone_age[0].concept_reasoner.filter_nn.weight[1, 1] = 10000.0\n",
    "    model.model.stone_age[0].concept_reasoner.filter_nn.weight[1, 2] = 10000.0\n",
    "    model.model.stone_age[0].concept_reasoner.sign_nn.weight[:] = 0\n",
    "    model.model.stone_age[0].concept_reasoner.sign_nn.weight[magical_idx, 0] = 10000.0\n",
    "    model.model.stone_age[0].concept_reasoner.sign_nn.weight[magical_idx, 1] = -10000.0\n",
    "    model.model.stone_age[0].concept_reasoner.sign_nn.weight[1, 1] = -10000.0\n",
    "    model.model.stone_age[0].concept_reasoner.sign_nn.weight[1, 2] = 10000.0\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[-10000., -10000., -10000.],\n",
       "        [-10000.,  10000.,  10000.],\n",
       "        [-10000., -10000., -10000.],\n",
       "        [-10000., -10000., -10000.],\n",
       "        [-10000., -10000., -10000.],\n",
       "        [-10000., -10000., -10000.],\n",
       "        [-10000., -10000., -10000.],\n",
       "        [-10000., -10000., -10000.],\n",
       "        [-10000., -10000., -10000.],\n",
       "        [-10000., -10000., -10000.],\n",
       "        [-10000., -10000., -10000.],\n",
       "        [-10000., -10000., -10000.],\n",
       "        [-10000., -10000., -10000.],\n",
       "        [-10000., -10000., -10000.],\n",
       "        [-10000., -10000., -10000.],\n",
       "        [-10000., -10000., -10000.],\n",
       "        [-10000., -10000., -10000.],\n",
       "        [-10000., -10000., -10000.],\n",
       "        [-10000., -10000., -10000.],\n",
       "        [-10000., -10000., -10000.],\n",
       "        [ 10000.,  10000., -10000.],\n",
       "        [-10000., -10000., -10000.],\n",
       "        [-10000., -10000., -10000.],\n",
       "        [-10000., -10000., -10000.],\n",
       "        [-10000., -10000., -10000.],\n",
       "        [-10000., -10000., -10000.],\n",
       "        [-10000., -10000., -10000.],\n",
       "        [-10000., -10000., -10000.],\n",
       "        [-10000., -10000., -10000.],\n",
       "        [-10000., -10000., -10000.],\n",
       "        [-10000., -10000., -10000.],\n",
       "        [-10000., -10000., -10000.],\n",
       "        [-10000., -10000., -10000.]], requires_grad=True)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.model.stone_age[0].concept_reasoner.filter_nn.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.2712, 0.2712, 0.2712],\n",
       "        [0.0000, 1.0000, 1.0000],\n",
       "        [0.2712, 0.2712, 0.2712],\n",
       "        [0.2712, 0.2712, 0.2712],\n",
       "        [0.2712, 0.2712, 0.2712],\n",
       "        [0.2712, 0.2712, 0.2712],\n",
       "        [0.2712, 0.2712, 0.2712],\n",
       "        [0.2712, 0.2712, 0.2712],\n",
       "        [0.2712, 0.2712, 0.2712],\n",
       "        [0.2712, 0.2712, 0.2712],\n",
       "        [0.2712, 0.2712, 0.2712],\n",
       "        [0.2712, 0.2712, 0.2712],\n",
       "        [0.2712, 0.2712, 0.2712],\n",
       "        [0.2712, 0.2712, 0.2712],\n",
       "        [0.2712, 0.2712, 0.2712],\n",
       "        [0.2712, 0.2712, 0.2712],\n",
       "        [0.2712, 0.2712, 0.2712],\n",
       "        [0.2712, 0.2712, 0.2712],\n",
       "        [0.2712, 0.2712, 0.2712],\n",
       "        [0.2712, 0.2712, 0.2712],\n",
       "        [1.0000, 1.0000, 0.0000],\n",
       "        [0.2712, 0.2712, 0.2712],\n",
       "        [0.2712, 0.2712, 0.2712],\n",
       "        [0.2712, 0.2712, 0.2712],\n",
       "        [0.2712, 0.2712, 0.2712],\n",
       "        [0.2712, 0.2712, 0.2712],\n",
       "        [0.2712, 0.2712, 0.2712],\n",
       "        [0.2712, 0.2712, 0.2712],\n",
       "        [0.2712, 0.2712, 0.2712],\n",
       "        [0.2712, 0.2712, 0.2712],\n",
       "        [0.2712, 0.2712, 0.2712],\n",
       "        [0.2712, 0.2712, 0.2712],\n",
       "        [0.2712, 0.2712, 0.2712]], grad_fn=<SigmoidBackward0>)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from bronze_age.models.concept_reasoner import softselect\n",
    "softselect(model.model.stone_age[0].concept_reasoner.filter_nn.weight, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0000, 0.0000, 1.0000],\n",
       "        [0.0000, 1.0000, 0.0000],\n",
       "        [0.0000, 1.0000, 0.0000],\n",
       "        [0.0000, 0.0000, 1.0000],\n",
       "        [1.0000, 0.0000, 0.0000],\n",
       "        [0.0000, 0.0000, 1.0000],\n",
       "        [0.0000, 0.0000, 1.0000],\n",
       "        [0.0000, 1.0000, 0.0000],\n",
       "        [1.0000, 0.0000, 0.4169],\n",
       "        [0.0000, 0.0000, 1.0000]], grad_fn=<SqueezeBackward1>)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = torch.randn(10, 33)\n",
    "X[:, magical_idx] = 0.0\n",
    "X[::4, magical_idx] = 1.0\n",
    "X[::3, 1] = 1.0\n",
    "\n",
    "model.model.stone_age[0].concept_reasoner(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[True, True, True],\n",
       "        [True, True, True],\n",
       "        [True, True, True],\n",
       "        ...,\n",
       "        [True, True, True],\n",
       "        [True, True, True],\n",
       "        [True, True, True]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.model.input.forward(dataset[0].x) == dataset[0].x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([3.0870e-07, 3.0870e-07, 3.0870e-07,  ..., 1.0000e+00, 1.0000e+00,\n",
       "         1.0000e+00], grad_fn=<SelectBackward0>),\n",
       " tensor([1, 1, 1,  ..., 1, 1, 1]))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.model.stone_age[0](dataset[0].x, dataset[0].edge_index)[:, 0], 1 - dataset[0].y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[0., 0., 0., 1., 0., 1.],\n",
       "        [0., 0., 0., 0., 1., 0.],\n",
       "        [0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0.]], requires_grad=True)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    model.model.output.lin2.lins[0].weight[:] = 0\n",
    "    model.model.output.lin2.lins[0].bias[:] = 0\n",
    "    model.model.output.lin2.lins[0].weight[:2, -3:-1] = torch.eye(2)\n",
    "    model.model.output.lin2.lins[0].weight[0, -1] = 1\n",
    "\n",
    "model.model.output.lin2.lins[0].weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    model.model.output.lin2.lins[1].weight[:] = 0\n",
    "    model.model.output.lin2.lins[1].bias[:] = 0\n",
    "    model.model.output.lin2.lins[1].weight[:2, :2] = torch.eye(2)\n",
    "\n",
    "model.model.output.lin2.lins[1].weight\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.3133, -1.3133],\n",
       "        [-0.3133, -1.3133],\n",
       "        [-0.3133, -1.3133],\n",
       "        ...,\n",
       "        [-0.3133, -1.3133],\n",
       "        [-0.3133, -1.3133],\n",
       "        [-0.3133, -1.3133]], grad_fn=<LogSoftmaxBackward0>)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = dataset[0].x\n",
    "edge_index = dataset[0].edge_index\n",
    "\n",
    "x = model.model.input(x.float())\n",
    "xs = [x]\n",
    "for layer in model.model.stone_age:\n",
    "    x = layer(x, edge_index, explain=False)\n",
    "    xs.append(x)\n",
    "\n",
    "x_prime = torch.cat(xs, dim=1)\n",
    "x_prime = model.model.output(x_prime)\n",
    "x_prime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[True, True, True],\n",
       "        [True, True, True],\n",
       "        [True, True, True],\n",
       "        ...,\n",
       "        [True, True, True],\n",
       "        [True, True, True],\n",
       "        [True, True, True]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(xs[0] == dataset[0].x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 1.],\n",
       "        [0., 0., 1.],\n",
       "        [0., 0., 1.],\n",
       "        ...,\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.]], grad_fn=<RoundBackward0>)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xs[1].round()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0, 0, 0,  ..., 0, 0, 0]), tensor([0, 0, 0,  ..., 0, 0, 0]))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.argmax(model.model(dataset[0].x, dataset[0].edge_index), dim=1), dataset[0].y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(1.0)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy\n",
    "y_pred = torch.argmax(model.model(dataset[0].x, dataset[0].edge_index), dim=1)\n",
    "y_true = dataset[0].y\n",
    "numpy.mean((y_pred == y_true).numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c55add1f5c73424a88b24765ec045528",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer  0\n",
      "[{'class': 'y_0', 'explanation': 's_1_count>7', 'count': 594}, {'class': 'y_1', 'explanation': '~s_1 & ~s_1_count>7', 'count': 1396}, {'class': 'y_2', 'explanation': 's_1', 'count': 10}]\n",
      "Layer  0\n",
      "[{'class': 'y_0', 'explanation': 's_1_count>7', 'count': 594}, {'class': 'y_1', 'explanation': '~s_1 & ~s_1_count>7', 'count': 1396}, {'class': 'y_2', 'explanation': 's_1', 'count': 10}]\n",
      "Layer  0\n",
      "[{'class': 'y_0', 'explanation': 's_1_count>7', 'count': 594}, {'class': 'y_1', 'explanation': '~s_1 & ~s_1_count>7', 'count': 1396}, {'class': 'y_2', 'explanation': 's_1', 'count': 10}]\n",
      "Layer  0\n",
      "[{'class': 'y_0', 'explanation': 's_1_count>7', 'count': 594}, {'class': 'y_1', 'explanation': '~s_1 & ~s_1_count>7', 'count': 1396}, {'class': 'y_2', 'explanation': 's_1', 'count': 10}]\n",
      "Layer  0\n",
      "[{'class': 'y_0', 'explanation': 's_1_count>7', 'count': 594}, {'class': 'y_1', 'explanation': '~s_1 & ~s_1_count>7', 'count': 1396}, {'class': 'y_2', 'explanation': 's_1', 'count': 10}]\n",
      "Layer  0\n",
      "[{'class': 'y_0', 'explanation': 's_1_count>7', 'count': 594}, {'class': 'y_1', 'explanation': '~s_1 & ~s_1_count>7', 'count': 1396}, {'class': 'y_2', 'explanation': 's_1', 'count': 10}]\n",
      "Layer  0\n",
      "[{'class': 'y_0', 'explanation': 's_1_count>7', 'count': 594}, {'class': 'y_1', 'explanation': '~s_1 & ~s_1_count>7', 'count': 1396}, {'class': 'y_2', 'explanation': 's_1', 'count': 10}]\n",
      "Layer  0\n",
      "[{'class': 'y_0', 'explanation': 's_1_count>7', 'count': 594}, {'class': 'y_1', 'explanation': '~s_1 & ~s_1_count>7', 'count': 1396}, {'class': 'y_2', 'explanation': 's_1', 'count': 10}]\n",
      "Layer  0\n",
      "[{'class': 'y_0', 'explanation': 's_1_count>7', 'count': 594}, {'class': 'y_1', 'explanation': '~s_1 & ~s_1_count>7', 'count': 1396}, {'class': 'y_2', 'explanation': 's_1', 'count': 10}]\n",
      "Layer  0\n",
      "[{'class': 'y_0', 'explanation': 's_1_count>7', 'count': 594}, {'class': 'y_1', 'explanation': '~s_1 & ~s_1_count>7', 'count': 1396}, {'class': 'y_2', 'explanation': 's_1', 'count': 10}]\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_acc                    1.0\n",
      "        test_loss           0.3139800727367401\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'test_loss': 0.3139800727367401, 'test_acc': 1.0}]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch_geometric.loader import DataLoader\n",
    "trainer = pl.Trainer(max_epochs=100, accelerator='mps')\n",
    "\n",
    "test_dataloader = DataLoader(dataset, batch_size=1, num_workers=0)\n",
    "trainer.test(model, dataloaders=test_dataloader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
